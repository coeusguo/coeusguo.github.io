
<!DOCTYPE HTML>
<html>

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-EHLYGK132J"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-EHLYGK132J');
    </script>

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@100;300;400&display=swap" rel="stylesheet">

	<title>STCN</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

    <link href="style.css" type="text/css" rel="stylesheet" media="screen,projection"/>
</head>

<body>
<br><br><br><br>
<div class="container">
        <div class="row text-center" style="font-size:38px">
            <div class="col">
                Multi-scale Cooperative Learning for Training Efficient Visual Transformers
            </div>
        </div>

        <br>
        <div class="row text-center" style="font-size:28px">
            <div class="col">
            IJCV Submission Under Review
            </div>
        </div>
        <br>

        <div class="h-100 row text-center heavy justify-content-md-center" style="font-size:24px;">
            <div class="col-sm-3">
                Jiangfan Han*
            </div>
            <div class="col-sm-3">
                <a href="https://hkchengrex.github.io/">Shaopeng Guo*</a>
            </div>

            <div class="col-sm-3">
                Jianbo Liu*
            </div>
            <div class="col-sm-3">
                Kun Yuan
            </div>
            <div class="col-sm-3">
                Hongsheng Li
            </div>
            <div class="col-sm-3">
                Xiaogang Wang
            </div>
        </div>

        <br>

        <div class="h-100 row text-center justify-content-md-center" style="font-size:20px;">
            <div class="col-sm-2">
                [Paper]
            </div>
            <div class="col-sm-2">
                [Code]
            </div>
        </div>

    <br>
    <hr>

    <div class="row" style="font-size:32px">
        <div class="col">
        Abstract
        </div>
    </div>
    <div class="row">
        <div class="col">
            <p style="text-align: justify;">
                Recently, visual Transformers have showed great potential on various computer vision tasks. 
                However, the large computational complexity might limit their applications on devices with constrained computing resources.
                Designing an efficient Transformer suitable for visual tasks is an urgent problem to be solved.
                Previous works showed that a larger patch size can significantly decreases the computational cost, as the number of patch embedding is decreased, but a larger patch size also leads to decreased final performance.
                Therefore, we propose a Multi-scale Cooperative Learning (MCL) framework to train an efficient visual Transformer. 
                With the help of the proposed patch compression mechanism, MCL trains the visual Transformer model with smaller and larger patches simultaneously.
                Besides, a decompression module is introduced to relieve information loss during patch compression.
                After training, the embedding and compression modules are re-parameterized into a unified operation with for efficient inference with only the large patch size.
                Experiments on different visual Transformer architectures show the effectiveness and generalization ability of our MCL approach. 
                For example, on ImageNet dataset, our MCL-DeiT-S/32 outperforms DeiT-Ti/16 by 3.4% with 1.5x faster inference speed. 
                It also outperforms MobileNetV2-1.0$\times$ and RegNetY-400MF by 3.3% and 1.5% respectively while being faster than both of them.
            </p>
        </div>
    </div>

    <br>
    <hr>
    <div class="row" style="font-size:32px">
        <div class="col">
        Network Architecture
        </div>
    </div>
    <br>
    <div class="h-100 row text-center justify-content-md-center">
        <div class="col">
            <img width="100%" src="images/mcl_arch.png" alt="framework">
        </div>
    </div>

    <br>
    <div class="row">
        <div class="col">
            <p style="text-align: justify;">
                Illustration of the proposed Multi-scale Cooperative Learning framework. 
                (Top) The training phase. The input image is transformed into patch embeddings of the small patch size, then combined and projected into fewer patch embeddings corresponding to larger patches. 
                A transposed projection module is adopted to reconstruct the initial patch embeddings. 
                All the patch embeddings are fed into the visual Transformer for joint learning.
                (Lower) The inference phase. Only the patch embedding generated by the largest patch size is used for efficient inference. 
            </p>
        </div>
    </div>
    <br>
    <div class="h-100 row text-center justify-content-md-center">
        <div class="col">
            <img width="100%" src="images/mcl_merge.png" alt="framework">
        </div>
    </div>

    <br>
    <div class="row">
        <div class="col">
            <p style="text-align: justify;">
                The combining and projection module is only used during training. 
                When used for inference, the two projection matrices can be merged into a single one via re-parameterization as both projections are linear operations.
            </p>
        </div>
    </div>
    <br>
    <hr>

    <br><br>

    <div style="font-size: 14px;">
        Contact: Shaopeng Guo sguoad@connect.ust.hk
        <br>
        <div style="color: lightgray;">
            Website modified from: https://github.com/ajabri/videowalk/blob/master/index.html
        </div>
    </div>

    <br><br>

</div>

</body>
</html>
